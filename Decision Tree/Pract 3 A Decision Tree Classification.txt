# Decision Tree Classification

# Importing the dataset
dataset = read.csv("E:\\Msc IT Part_1\\SEM_2\\Practical\\Rahul\\BIG DATA ANALYTICS\\Decision Tree\\socialnetworking.csv")
#print(dataset)
dataset = dataset[3:5] # columns 3 4 ad 5
print(dataset)

# Encoding the target feature as factor(just like a vector having levels
# levels to convey that only two possible values for purchased - 0 & 1
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
print (dataset$Purchased)

# Splitting the dataset into the Training set and Test set
install.packages('caTools')
library(caTools)
set.seed(123)
#split = sample.split(dataset$Purchased, SplitRatio = 0.75)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)

# Feature Scaling - scale() method centers and/or scales the #columns of a numeric matrix.
training_set[-3] = scale(training_set[-3]) 
# scaling first 2 columns, don't consider 3rd column
test_set[-3] = scale(test_set[-3])
#print(test_set[-3])

# Fitting Decision Tree Classification to the Training set
install.packages('rpart')
library(rpart) # for partitioning tree
install.packages('rpart.plot')
library(rpart.plot)

classifier = rpart(formula = Purchased ~ .,data = training_set)

# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-3], type = 'class')
print(y_pred)

# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred)
print(cm)

# Plotting the tree
#extra=106 class model with a binary response
#extra=104 class model with a response having more than two #levels
rpart.plot(classifier, extra = 106)

#or
#library("party")
#print(head(readingSkills))
#str(iris)
#iris_ctree <- ctree(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data = iris)
#print(iris_ctree)
#plot(iris_ctree)

